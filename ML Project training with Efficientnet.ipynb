{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.EfficientNetB0",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqtvoltYSP2L",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNdGJ93XfMKN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "430d7bd9-56e8-47a3-f862-8a18aecde400"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPxAkt4TQIHK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 750
        },
        "outputId": "1db84553-9f57-4143-ec4d-8d5131026cfe"
      },
      "source": [
        "!git clone https://github.com/Tony607/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning\n",
        "\n",
        "\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input\n",
        "\n",
        "conv_base = Net(weights = \"imagenet\", include_top = False)\n",
        "\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "\n",
        "dropout_rate = 0.2 \n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "model.add(layers.Flatten(name = \"flatten\"))\n",
        "model.add(layers.Dense(196, activation = 'softmax', name = \"fc_out\"))\n",
        "model.load_weights('/content/gdrive/My Drive/MLDS/model_weights_2.h5')\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'efficientnet_keras_transfer_learning'...\n",
            "remote: Enumerating objects: 171, done.\u001b[K\n",
            "remote: Counting objects: 100% (171/171), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 171 (delta 98), reused 161 (delta 93), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (171/171), 5.44 MiB | 7.69 MiB/s, done.\n",
            "Resolving deltas: 100% (98/98), done.\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/efficientnet_keras_transfer_learning/efficientnet/model.py:67: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/efficientnet_keras_transfer_learning/efficientnet/layers.py:30: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\n",
            "16719872/16717576 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnet-b0 (Model)      (None, 7, 7, 1280)        4049564   \n",
            "_________________________________________________________________\n",
            "gap (GlobalMaxPooling2D)     (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "fc_out (Dense)               (None, 196)               251076    \n",
            "=================================================================\n",
            "Total params: 4,300,640\n",
            "Trainable params: 4,258,624\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v51S1ddrnKEp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9ev_Ni7Ie304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5afd41cd-af8c-40b5-fdcd-76986a1c83c3"
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 50\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import optimizers\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1. / 255,\n",
        "                                   rotation_range = 10,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('/content/gdrive/My Drive/MLDS/x_train_jpeg',\n",
        "                                                    target_size = (224, 224),\n",
        "                                                    batch_size = batch_size, \n",
        "                                                    class_mode = \"categorical\")\n",
        "\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    '/content/gdrive/My Drive/MLDS/x_val_jpeg',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "def top_5_categorical_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k = 5)\n",
        "\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "              optimizer = optimizers.Adam(lr = 1e-5),\n",
        "              metrics = ['acc', top_5_categorical_accuracy])\n",
        "          \n",
        "\n",
        "hist =model.fit_generator(train_generator, steps_per_epoch = 8144 // batch_size, \n",
        "                          epochs = epochs,validation_data = validation_generator,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "train_acc = hist.history['acc']\n",
        "val_acc = hist.history['val_acc']\n",
        "\n",
        "train_loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "\n",
        "print(train_acc)\n",
        "print(val_acc)\n",
        "print(train_loss)\n",
        "print(val_loss)\n",
        "\n",
        "\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "plt.plot(epochs, train_acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label=\"Val acc\")\n",
        "plt.title('Training anc Val accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Val loss')\n",
        "plt.title('Training and Val loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6000 images belonging to 196 classes.\n",
            "Found 2144 images belonging to 196 classes.\n",
            "Epoch 1/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0615 - acc: 0.9877 - top_5_categorical_accuracy: 0.9998Epoch 1/50\n",
            "127/127 [==============================] - 204s 2s/step - loss: 0.0623 - acc: 0.9874 - top_5_categorical_accuracy: 0.9998 - val_loss: 1.7020 - val_acc: 0.6301 - val_top_5_categorical_accuracy: 0.8517\n",
            "Epoch 2/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0655 - acc: 0.9842 - top_5_categorical_accuracy: 0.9993Epoch 1/50\n",
            "127/127 [==============================] - 180s 1s/step - loss: 0.0653 - acc: 0.9843 - top_5_categorical_accuracy: 0.9993 - val_loss: 1.6891 - val_acc: 0.6334 - val_top_5_categorical_accuracy: 0.8545\n",
            "Epoch 3/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0635 - acc: 0.9868 - top_5_categorical_accuracy: 0.9991Epoch 1/50\n",
            "127/127 [==============================] - 176s 1s/step - loss: 0.0634 - acc: 0.9868 - top_5_categorical_accuracy: 0.9991 - val_loss: 1.6879 - val_acc: 0.6343 - val_top_5_categorical_accuracy: 0.8540\n",
            "Epoch 4/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0637 - acc: 0.9846 - top_5_categorical_accuracy: 0.9995Epoch 1/50\n",
            "127/127 [==============================] - 176s 1s/step - loss: 0.0635 - acc: 0.9847 - top_5_categorical_accuracy: 0.9995 - val_loss: 1.6886 - val_acc: 0.6367 - val_top_5_categorical_accuracy: 0.8531\n",
            "Epoch 5/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0593 - acc: 0.9864 - top_5_categorical_accuracy: 0.9991Epoch 1/50\n",
            "127/127 [==============================] - 177s 1s/step - loss: 0.0593 - acc: 0.9864 - top_5_categorical_accuracy: 0.9991 - val_loss: 1.6659 - val_acc: 0.6367 - val_top_5_categorical_accuracy: 0.8563\n",
            "Epoch 6/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0563 - acc: 0.9868 - top_5_categorical_accuracy: 0.9993Epoch 1/50\n",
            "127/127 [==============================] - 176s 1s/step - loss: 0.0562 - acc: 0.9868 - top_5_categorical_accuracy: 0.9993 - val_loss: 1.6639 - val_acc: 0.6423 - val_top_5_categorical_accuracy: 0.8573\n",
            "Epoch 7/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0622 - acc: 0.9862 - top_5_categorical_accuracy: 0.9993Epoch 1/50\n",
            "127/127 [==============================] - 177s 1s/step - loss: 0.0619 - acc: 0.9863 - top_5_categorical_accuracy: 0.9993 - val_loss: 1.6558 - val_acc: 0.6418 - val_top_5_categorical_accuracy: 0.8605\n",
            "Epoch 8/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0609 - acc: 0.9865 - top_5_categorical_accuracy: 0.9993Epoch 1/50\n",
            "127/127 [==============================] - 177s 1s/step - loss: 0.0608 - acc: 0.9866 - top_5_categorical_accuracy: 0.9993 - val_loss: 1.6529 - val_acc: 0.6409 - val_top_5_categorical_accuracy: 0.8633\n",
            "Epoch 9/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0562 - acc: 0.9871 - top_5_categorical_accuracy: 0.9998Epoch 1/50\n",
            "127/127 [==============================] - 176s 1s/step - loss: 0.0562 - acc: 0.9869 - top_5_categorical_accuracy: 0.9998 - val_loss: 1.6451 - val_acc: 0.6409 - val_top_5_categorical_accuracy: 0.8610\n",
            "Epoch 10/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0536 - acc: 0.9872 - top_5_categorical_accuracy: 0.9998Epoch 1/50\n",
            "127/127 [==============================] - 177s 1s/step - loss: 0.0538 - acc: 0.9872 - top_5_categorical_accuracy: 0.9998 - val_loss: 1.6436 - val_acc: 0.6409 - val_top_5_categorical_accuracy: 0.8638\n",
            "Epoch 11/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0548 - acc: 0.9882 - top_5_categorical_accuracy: 0.9989Epoch 1/50\n",
            "127/127 [==============================] - 175s 1s/step - loss: 0.0546 - acc: 0.9883 - top_5_categorical_accuracy: 0.9989 - val_loss: 1.6451 - val_acc: 0.6395 - val_top_5_categorical_accuracy: 0.8601\n",
            "Epoch 12/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0490 - acc: 0.9901 - top_5_categorical_accuracy: 0.9996Epoch 1/50\n",
            "127/127 [==============================] - 178s 1s/step - loss: 0.0488 - acc: 0.9901 - top_5_categorical_accuracy: 0.9996 - val_loss: 1.6522 - val_acc: 0.6390 - val_top_5_categorical_accuracy: 0.8582\n",
            "Epoch 13/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0490 - acc: 0.9893 - top_5_categorical_accuracy: 0.9996Epoch 1/50\n",
            "127/127 [==============================] - 180s 1s/step - loss: 0.0488 - acc: 0.9894 - top_5_categorical_accuracy: 0.9996 - val_loss: 1.6574 - val_acc: 0.6460 - val_top_5_categorical_accuracy: 0.8624\n",
            "Epoch 14/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0531 - acc: 0.9887 - top_5_categorical_accuracy: 0.9996Epoch 1/50\n",
            "127/127 [==============================] - 176s 1s/step - loss: 0.0531 - acc: 0.9885 - top_5_categorical_accuracy: 0.9996 - val_loss: 1.6536 - val_acc: 0.6371 - val_top_5_categorical_accuracy: 0.8619\n",
            "Epoch 15/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0487 - acc: 0.9887 - top_5_categorical_accuracy: 0.9998Epoch 1/50\n",
            "127/127 [==============================] - 181s 1s/step - loss: 0.0486 - acc: 0.9888 - top_5_categorical_accuracy: 0.9998 - val_loss: 1.6453 - val_acc: 0.6437 - val_top_5_categorical_accuracy: 0.8638\n",
            "Epoch 16/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0514 - acc: 0.9884 - top_5_categorical_accuracy: 0.9990Epoch 1/50\n",
            "127/127 [==============================] - 177s 1s/step - loss: 0.0516 - acc: 0.9884 - top_5_categorical_accuracy: 0.9990 - val_loss: 1.6638 - val_acc: 0.6446 - val_top_5_categorical_accuracy: 0.8638\n",
            "Epoch 17/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0450 - acc: 0.9904 - top_5_categorical_accuracy: 0.9999Epoch 1/50\n",
            "127/127 [==============================] - 171s 1s/step - loss: 0.0449 - acc: 0.9905 - top_5_categorical_accuracy: 0.9999 - val_loss: 1.6537 - val_acc: 0.6404 - val_top_5_categorical_accuracy: 0.8605\n",
            "Epoch 18/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0476 - acc: 0.9898 - top_5_categorical_accuracy: 0.9995Epoch 1/50\n",
            "127/127 [==============================] - 185s 1s/step - loss: 0.0473 - acc: 0.9899 - top_5_categorical_accuracy: 0.9995 - val_loss: 1.6535 - val_acc: 0.6446 - val_top_5_categorical_accuracy: 0.8638\n",
            "Epoch 19/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0452 - acc: 0.9907 - top_5_categorical_accuracy: 0.9999Epoch 1/50\n",
            "127/127 [==============================] - 177s 1s/step - loss: 0.0457 - acc: 0.9906 - top_5_categorical_accuracy: 0.9998 - val_loss: 1.6556 - val_acc: 0.6460 - val_top_5_categorical_accuracy: 0.8675\n",
            "Epoch 20/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0512 - acc: 0.9875 - top_5_categorical_accuracy: 0.9995Epoch 1/50\n",
            "127/127 [==============================] - 175s 1s/step - loss: 0.0512 - acc: 0.9875 - top_5_categorical_accuracy: 0.9995 - val_loss: 1.6528 - val_acc: 0.6446 - val_top_5_categorical_accuracy: 0.8638\n",
            "Epoch 21/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0422 - acc: 0.9907 - top_5_categorical_accuracy: 0.9998Epoch 1/50\n",
            "127/127 [==============================] - 178s 1s/step - loss: 0.0421 - acc: 0.9907 - top_5_categorical_accuracy: 0.9998 - val_loss: 1.6580 - val_acc: 0.6441 - val_top_5_categorical_accuracy: 0.8629\n",
            "Epoch 22/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0429 - acc: 0.9899 - top_5_categorical_accuracy: 1.0000Epoch 1/50\n",
            "127/127 [==============================] - 179s 1s/step - loss: 0.0429 - acc: 0.9900 - top_5_categorical_accuracy: 1.0000 - val_loss: 1.6578 - val_acc: 0.6474 - val_top_5_categorical_accuracy: 0.8615\n",
            "Epoch 23/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0432 - acc: 0.9911 - top_5_categorical_accuracy: 0.9999Epoch 1/50\n",
            "127/127 [==============================] - 181s 1s/step - loss: 0.0433 - acc: 0.9911 - top_5_categorical_accuracy: 0.9999 - val_loss: 1.6362 - val_acc: 0.6469 - val_top_5_categorical_accuracy: 0.8638\n",
            "Epoch 24/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0424 - acc: 0.9908 - top_5_categorical_accuracy: 0.9994Epoch 1/50\n",
            "127/127 [==============================] - 180s 1s/step - loss: 0.0431 - acc: 0.9904 - top_5_categorical_accuracy: 0.9994 - val_loss: 1.6392 - val_acc: 0.6525 - val_top_5_categorical_accuracy: 0.8647\n",
            "Epoch 25/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0457 - acc: 0.9901 - top_5_categorical_accuracy: 0.9996Epoch 1/50\n",
            "127/127 [==============================] - 181s 1s/step - loss: 0.0457 - acc: 0.9900 - top_5_categorical_accuracy: 0.9996 - val_loss: 1.6443 - val_acc: 0.6451 - val_top_5_categorical_accuracy: 0.8647\n",
            "Epoch 26/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0439 - acc: 0.9902 - top_5_categorical_accuracy: 0.9996Epoch 1/50\n",
            "127/127 [==============================] - 180s 1s/step - loss: 0.0439 - acc: 0.9902 - top_5_categorical_accuracy: 0.9996 - val_loss: 1.6350 - val_acc: 0.6465 - val_top_5_categorical_accuracy: 0.8680\n",
            "Epoch 27/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0385 - acc: 0.9912 - top_5_categorical_accuracy: 0.9999Epoch 1/50\n",
            "127/127 [==============================] - 182s 1s/step - loss: 0.0384 - acc: 0.9912 - top_5_categorical_accuracy: 0.9999 - val_loss: 1.6312 - val_acc: 0.6488 - val_top_5_categorical_accuracy: 0.8685\n",
            "Epoch 28/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0405 - acc: 0.9914 - top_5_categorical_accuracy: 0.9998Epoch 1/50\n",
            "127/127 [==============================] - 181s 1s/step - loss: 0.0404 - acc: 0.9915 - top_5_categorical_accuracy: 0.9998 - val_loss: 1.6224 - val_acc: 0.6502 - val_top_5_categorical_accuracy: 0.8671\n",
            "Epoch 29/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0385 - acc: 0.9922 - top_5_categorical_accuracy: 0.9995Epoch 1/50\n",
            "127/127 [==============================] - 183s 1s/step - loss: 0.0384 - acc: 0.9922 - top_5_categorical_accuracy: 0.9995 - val_loss: 1.6488 - val_acc: 0.6446 - val_top_5_categorical_accuracy: 0.8633\n",
            "Epoch 30/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0397 - acc: 0.9918 - top_5_categorical_accuracy: 0.9996Epoch 1/50\n",
            "127/127 [==============================] - 183s 1s/step - loss: 0.0399 - acc: 0.9917 - top_5_categorical_accuracy: 0.9996 - val_loss: 1.6558 - val_acc: 0.6460 - val_top_5_categorical_accuracy: 0.8657\n",
            "Epoch 31/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0453 - acc: 0.9897 - top_5_categorical_accuracy: 0.9994Epoch 1/50\n",
            "127/127 [==============================] - 183s 1s/step - loss: 0.0451 - acc: 0.9898 - top_5_categorical_accuracy: 0.9994 - val_loss: 1.6526 - val_acc: 0.6465 - val_top_5_categorical_accuracy: 0.8699\n",
            "Epoch 32/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0376 - acc: 0.9922 - top_5_categorical_accuracy: 0.9996Epoch 1/50\n",
            "127/127 [==============================] - 186s 1s/step - loss: 0.0375 - acc: 0.9922 - top_5_categorical_accuracy: 0.9996 - val_loss: 1.6546 - val_acc: 0.6474 - val_top_5_categorical_accuracy: 0.8680\n",
            "Epoch 33/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0386 - acc: 0.9916 - top_5_categorical_accuracy: 0.9995Epoch 1/50\n",
            "127/127 [==============================] - 182s 1s/step - loss: 0.0391 - acc: 0.9914 - top_5_categorical_accuracy: 0.9994 - val_loss: 1.6290 - val_acc: 0.6516 - val_top_5_categorical_accuracy: 0.8671\n",
            "Epoch 34/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0383 - acc: 0.9912 - top_5_categorical_accuracy: 0.9998Epoch 1/50\n",
            "127/127 [==============================] - 180s 1s/step - loss: 0.0384 - acc: 0.9911 - top_5_categorical_accuracy: 0.9998 - val_loss: 1.6228 - val_acc: 0.6451 - val_top_5_categorical_accuracy: 0.8717\n",
            "Epoch 35/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0358 - acc: 0.9914 - top_5_categorical_accuracy: 1.0000Epoch 1/50\n",
            "127/127 [==============================] - 190s 1s/step - loss: 0.0358 - acc: 0.9915 - top_5_categorical_accuracy: 1.0000 - val_loss: 1.6296 - val_acc: 0.6497 - val_top_5_categorical_accuracy: 0.8699\n",
            "Epoch 36/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0363 - acc: 0.9934 - top_5_categorical_accuracy: 0.9999Epoch 1/50\n",
            "127/127 [==============================] - 185s 1s/step - loss: 0.0362 - acc: 0.9935 - top_5_categorical_accuracy: 0.9999 - val_loss: 1.6367 - val_acc: 0.6530 - val_top_5_categorical_accuracy: 0.8661\n",
            "Epoch 37/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0359 - acc: 0.9916 - top_5_categorical_accuracy: 0.9996Epoch 1/50\n",
            "127/127 [==============================] - 177s 1s/step - loss: 0.0358 - acc: 0.9916 - top_5_categorical_accuracy: 0.9996 - val_loss: 1.6369 - val_acc: 0.6549 - val_top_5_categorical_accuracy: 0.8680\n",
            "Epoch 38/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0367 - acc: 0.9924 - top_5_categorical_accuracy: 0.9994Epoch 1/50\n",
            "127/127 [==============================] - 197s 2s/step - loss: 0.0367 - acc: 0.9924 - top_5_categorical_accuracy: 0.9994 - val_loss: 1.6346 - val_acc: 0.6525 - val_top_5_categorical_accuracy: 0.8643\n",
            "Epoch 39/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0357 - acc: 0.9918 - top_5_categorical_accuracy: 1.0000Epoch 1/50\n",
            "127/127 [==============================] - 187s 1s/step - loss: 0.0359 - acc: 0.9916 - top_5_categorical_accuracy: 1.0000 - val_loss: 1.6251 - val_acc: 0.6553 - val_top_5_categorical_accuracy: 0.8666\n",
            "Epoch 40/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0357 - acc: 0.9913 - top_5_categorical_accuracy: 0.9999Epoch 1/50\n",
            "127/127 [==============================] - 184s 1s/step - loss: 0.0361 - acc: 0.9912 - top_5_categorical_accuracy: 0.9999 - val_loss: 1.6322 - val_acc: 0.6535 - val_top_5_categorical_accuracy: 0.8671\n",
            "Epoch 41/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0335 - acc: 0.9927 - top_5_categorical_accuracy: 0.9998Epoch 1/50\n",
            "127/127 [==============================] - 183s 1s/step - loss: 0.0335 - acc: 0.9926 - top_5_categorical_accuracy: 0.9998 - val_loss: 1.6130 - val_acc: 0.6562 - val_top_5_categorical_accuracy: 0.8647\n",
            "Epoch 42/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0309 - acc: 0.9934 - top_5_categorical_accuracy: 0.9998Epoch 1/50\n",
            "127/127 [==============================] - 182s 1s/step - loss: 0.0309 - acc: 0.9935 - top_5_categorical_accuracy: 0.9998 - val_loss: 1.6246 - val_acc: 0.6590 - val_top_5_categorical_accuracy: 0.8703\n",
            "Epoch 43/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0309 - acc: 0.9935 - top_5_categorical_accuracy: 0.9996Epoch 1/50\n",
            "127/127 [==============================] - 183s 1s/step - loss: 0.0309 - acc: 0.9935 - top_5_categorical_accuracy: 0.9996 - val_loss: 1.6246 - val_acc: 0.6558 - val_top_5_categorical_accuracy: 0.8694\n",
            "Epoch 44/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0303 - acc: 0.9939 - top_5_categorical_accuracy: 0.9996Epoch 1/50\n",
            "127/127 [==============================] - 183s 1s/step - loss: 0.0302 - acc: 0.9940 - top_5_categorical_accuracy: 0.9996 - val_loss: 1.6194 - val_acc: 0.6549 - val_top_5_categorical_accuracy: 0.8689\n",
            "Epoch 45/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0356 - acc: 0.9913 - top_5_categorical_accuracy: 0.9993Epoch 1/50\n",
            "127/127 [==============================] - 184s 1s/step - loss: 0.0355 - acc: 0.9914 - top_5_categorical_accuracy: 0.9993 - val_loss: 1.6184 - val_acc: 0.6572 - val_top_5_categorical_accuracy: 0.8703\n",
            "Epoch 46/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0326 - acc: 0.9923 - top_5_categorical_accuracy: 0.9999Epoch 1/50\n",
            "127/127 [==============================] - 183s 1s/step - loss: 0.0325 - acc: 0.9923 - top_5_categorical_accuracy: 0.9999 - val_loss: 1.6023 - val_acc: 0.6572 - val_top_5_categorical_accuracy: 0.8703\n",
            "Epoch 47/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0285 - acc: 0.9940 - top_5_categorical_accuracy: 0.9998Epoch 1/50\n",
            "127/127 [==============================] - 183s 1s/step - loss: 0.0284 - acc: 0.9941 - top_5_categorical_accuracy: 0.9998 - val_loss: 1.6102 - val_acc: 0.6590 - val_top_5_categorical_accuracy: 0.8680\n",
            "Epoch 48/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0322 - acc: 0.9922 - top_5_categorical_accuracy: 0.9998Epoch 1/50\n",
            "127/127 [==============================] - 183s 1s/step - loss: 0.0322 - acc: 0.9922 - top_5_categorical_accuracy: 0.9998 - val_loss: 1.6017 - val_acc: 0.6581 - val_top_5_categorical_accuracy: 0.8736\n",
            "Epoch 49/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0297 - acc: 0.9940 - top_5_categorical_accuracy: 0.9996Epoch 1/50\n",
            "127/127 [==============================] - 183s 1s/step - loss: 0.0297 - acc: 0.9941 - top_5_categorical_accuracy: 0.9996 - val_loss: 1.6141 - val_acc: 0.6535 - val_top_5_categorical_accuracy: 0.8699\n",
            "Epoch 50/50\n",
            "126/127 [============================>.] - ETA: 1s - loss: 0.0307 - acc: 0.9929 - top_5_categorical_accuracy: 0.9996Epoch 1/50\n",
            "127/127 [==============================] - 185s 1s/step - loss: 0.0307 - acc: 0.9929 - top_5_categorical_accuracy: 0.9996 - val_loss: 1.6114 - val_acc: 0.6628 - val_top_5_categorical_accuracy: 0.8713\n",
            "[0.98742604, 0.98431325, 0.9868097, 0.98471403, 0.98641306, 0.9868097, 0.9862895, 0.98656315, 0.98693293, 0.98717946, 0.9882658, 0.99013805, 0.9893775, 0.9885355, 0.98878205, 0.9884122, 0.9904891, 0.98987156, 0.99063116, 0.9875493, 0.9907362, 0.9900148, 0.9911243, 0.99038464, 0.9900148, 0.9902421, 0.99123025, 0.99149406, 0.99223375, 0.9917243, 0.98976827, 0.99223375, 0.9913708, 0.99110675, 0.99149406, 0.99345356, 0.9916174, 0.992357, 0.9916008, 0.99124753, 0.99260354, 0.99345356, 0.9934665, 0.99395955, 0.9913708, 0.9923419, 0.9940711, 0.992249, 0.9940711, 0.9928501]\n",
            "[0.6301306, 0.6333955, 0.63432837, 0.63666046, 0.63666046, 0.64225745, 0.64179105, 0.64085823, 0.64085823, 0.64085823, 0.63945895, 0.63899255, 0.6459888, 0.63712686, 0.64365673, 0.64458954, 0.64039177, 0.64458954, 0.6459888, 0.64458954, 0.64412314, 0.64738804, 0.64692163, 0.65251863, 0.64505595, 0.6464552, 0.6487873, 0.65018654, 0.64458954, 0.6459888, 0.6464552, 0.64738804, 0.6515858, 0.64505595, 0.64972013, 0.6529851, 0.6548507, 0.65251863, 0.6553172, 0.6534515, 0.65625, 0.6590485, 0.6557836, 0.6548507, 0.6571828, 0.6571828, 0.6590485, 0.6581157, 0.6534515, 0.66277987]\n",
            "[0.06233553969001864, 0.06531048598864922, 0.06339584252038416, 0.06361349396907248, 0.05897157826265799, 0.05629952487405353, 0.06191113706045, 0.060807973058266046, 0.05623031668438479, 0.053809631490966035, 0.05452363087018959, 0.04887881136960414, 0.04884908949080192, 0.05313950175276169, 0.0485749943090026, 0.05164667326200173, 0.04481634901829152, 0.047256502495865105, 0.04556173598301951, 0.05124537564476096, 0.042088364585939606, 0.042917498903573145, 0.0433607098133959, 0.04317353549000074, 0.04548964368756236, 0.043972242224166395, 0.038290777122196945, 0.04031272346789432, 0.03836653219201626, 0.03980860190296715, 0.045054697811868064, 0.03744854797890201, 0.03911733451709004, 0.038442070397139774, 0.035761017462558296, 0.03621154613130295, 0.03585627521856649, 0.03666210171988848, 0.035947388257065664, 0.036146828423472784, 0.033465965083364906, 0.030909161528815395, 0.030929742723563778, 0.03017095756336782, 0.03555173908417247, 0.03241033730255403, 0.028412288743192734, 0.032165091455452086, 0.02970452899510858, 0.030538549723886175]\n",
            "[1.7020419555551864, 1.6890886338318096, 1.687940958668204, 1.6885509999359356, 1.6659022709902596, 1.6638976878979628, 1.6558069306261398, 1.6529491543769836, 1.645058067405925, 1.6436393190832699, 1.6450974415330326, 1.6522159471231348, 1.6573772079804365, 1.653634563964956, 1.6453316264292772, 1.6637541581602657, 1.6537365212159998, 1.6535322175306433, 1.655598892885096, 1.6528100020745222, 1.6579893757315243, 1.6578269951483782, 1.6361917485209072, 1.6391805200015797, 1.6442590110442217, 1.6350387317292832, 1.6311942636966705, 1.6224057551692515, 1.6488199584624346, 1.6558369222809286, 1.6526267423349268, 1.6545994281768799, 1.6290143412702225, 1.6228145045392655, 1.6295837514540727, 1.6367349168833565, 1.6369081788203295, 1.6346213098834543, 1.6251286969465368, 1.6322060367640328, 1.613042249399073, 1.6246010345571182, 1.6246022091192358, 1.6194058902123396, 1.6183743371683008, 1.6023243244956522, 1.6101921481244705, 1.6016753841848934, 1.614125232486164, 1.6114335025058073]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-53a0b437968a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training acc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Val acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training anc Val accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DNtjNM1yRK4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f38b5935-0861-486b-cd20-89166222b4f6"
      },
      "source": [
        "# 모델 저장\n",
        "from keras.models import load_model\n",
        "\n",
        "model.save('/content/gdrive/My Drive/MLDS/MLDS_CNN_CAR196_6.h5')\n",
        "\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"/content/gdrive/My Drive/MLDS/model_6.json\", \"w\") as json_file : \n",
        "    json_file.write(model_json)\n",
        "\n",
        "\n",
        "model.save_weights(\"/content/gdrive/My Drive/MLDS/model_weights_6.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}